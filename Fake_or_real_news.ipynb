{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNcq0V0m/SM9Y2fCJ9ISlQk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O6IdYO3z33Hs"},"outputs":[],"source":["\n","from google.colab import files\n","uploaded = files.upload()\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import PassiveAggressiveClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","df = pd.read_csv('fake_or_real_news.csv')\n","print(\"Dataset Preview:\\n\", df.head())\n","X = df['text']\n","y = df['label']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","vectorizer = TfidfVectorizer(stop_words= 'english', max_df=0.7)\n","tfidf_train = vectorizer.fit_transform(X_train)\n","tfidf_test = vectorizer.transform(X_test)\n","model = PassiveAggressiveClassifier(max_iter= 50)\n","model.fit(tfidf_train, y_train)\n","y_pred = model.predict(tfidf_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"\\n Model Accuracy:{round(accuracy*100, 2)}%\")\n","cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\\n\", cm)\n","plt.figure(figsize= (6, 4))\n","sns.heatmap(cm, annot=True, fmt='d', cmap= 'Blues', xticklabels= ['Real', 'Fake'], yticklabels= ['Real', 'Fake'])\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title(' Fake News Detection - Confusion Matrix')\n","plt.show( )\n","plt.figure(figsize=(6, 4))\n","sns.countplot(x= 'label', data = df, palette= 'Set2')\n","plt.xticks([ 0, 1], ['Real', 'Fake'])\n","plt.title('News Type Distribution in Dataset')\n","plt.xlabel('News Type')\n","plt.ylabel('Count')\n","plt.show( )"]},{"cell_type":"code","source":["# Step 1: Import libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Step 2: CSV file load ‡§ï‡§∞‡•ã\n","df = pd.read_csv('fake_or_real_news.csv')  # üëà CSV ‡§´‡§æ‡§á‡§≤ ‡§á‡§∏‡•Ä ‡§®‡§æ‡§Æ ‡§∏‡•á ‡§π‡•ã‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è\n","\n","# Step 3: Data check ‡§ï‡§∞‡•á‡§Ç\n","print(df.head())\n","print(df['label'].value_counts())  # ‡§ï‡§ø‡§§‡§®‡•Ä real ‡§î‡§∞ fake news ‡§π‡•à‡§Ç\n","\n","# Step 4: Text ‡§î‡§∞ Label ‡§Ö‡§≤‡§ó ‡§ï‡§∞‡•á‡§Ç\n","X = df['text']   # ‡§®‡•ç‡§Ø‡•Ç‡§ú‡§º ‡§ï‡§æ main content\n","y = df['label']  # real ‡§Ø‡§æ fake\n","\n","# Step 5: Text ‡§ï‡•ã numerical features ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡•ã (TF-IDF)\n","vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n","X_vectorized = vectorizer.fit_transform(X)\n","\n","# Step 6: Train-Test Split (80% training, 20% testing)\n","X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n","\n","# Step 7: Logistic Regression Model Train ‡§ï‡§∞‡•ã\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# Step 8: Accuracy Check ‡§ï‡§∞‡•ã\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy*100:.2f}%\")\n","\n","# Step 9: Test Prediction\n","sample_news = [\"The government has passed a new law on data privacy.\"]\n","sample_vector = vectorizer.transform(sample_news)\n","print(\"Prediction:\", model.predict(sample_vector)[0])"],"metadata":{"id":"fS_6KrOSEytq"},"execution_count":null,"outputs":[]}]}